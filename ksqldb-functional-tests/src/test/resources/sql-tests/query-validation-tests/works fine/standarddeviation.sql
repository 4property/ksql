--@test: standarddeviation - stddev_sample int
CREATE STREAM TEST (ID BIGINT KEY, VALUE integer) WITH (kafka_topic='test_topic',value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_sample(value) AS stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, 0);
INSERT INTO `TEST` (ID, value) VALUES (0, 10);
INSERT INTO `TEST` (ID, value) VALUES (100, 50);
INSERT INTO `TEST` (ID, value) VALUES (100, 10);
INSERT INTO `TEST` (ID, value) VALUES (0, 7);
INSERT INTO `TEST` (ID, value) VALUES (100, 3);
INSERT INTO `TEST` (ID, value) VALUES (100, NULL);
INSERT INTO `TEST` (ID, value) VALUES (0, 6);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 7.0710678118654755);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 28.284271247461902);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 5.131601439446884);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 25.357444666211933);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 25.357444666211933);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 4.193248541803041);

--@test: standarddeviation - stddev_sample long
CREATE STREAM TEST (ID BIGINT KEY, VALUE bigint) WITH (kafka_topic='test_topic', value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_sample(value) as stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, 2147483648);
INSERT INTO `TEST` (ID, value) VALUES (0, 100);
INSERT INTO `TEST` (ID, value) VALUES (100, 500);
INSERT INTO `TEST` (ID, value) VALUES (100, 100);
INSERT INTO `TEST` (ID, value) VALUES (0, -2);
INSERT INTO `TEST` (ID, value) VALUES (100, 0);
INSERT INTO `TEST` (ID, value) VALUES (100, -6);
INSERT INTO `TEST` (ID, value) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1518500179.2773468);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 282.842712474619);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1239850233.9629574);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 264.5751311064591);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 239.32335169528832);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1239850233.9629574);

--@test: standarddeviation - stddev_sample double
CREATE STREAM TEST (ID BIGINT KEY, VALUE double) WITH (kafka_topic='test_topic', value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_sample(value) as stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, -1.8);
INSERT INTO `TEST` (ID, value) VALUES (0, 2.3);
INSERT INTO `TEST` (ID, value) VALUES (100, 9223372036854.775807);
INSERT INTO `TEST` (ID, value) VALUES (100, 300.8);
INSERT INTO `TEST` (ID, value) VALUES (0, 100.2);
INSERT INTO `TEST` (ID, value) VALUES (100, -200000.6);
INSERT INTO `TEST` (ID, value) VALUES (100, 0.0);
INSERT INTO `TEST` (ID, value) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2.899137802864845);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 6521908912453.693);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 57.74256084841869);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 5325116385962.54);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 4611686051710.689);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 57.74256084841869);

--@test: standarddeviation - stddev_sample double map
CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE map<varchar, double>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT as SELECT ID, stddev_sample(value['key1']) AS STDDEV FROM test group by id;
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=10.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=12.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=13.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=14.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=16.0, 'key2':=1.0));
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1.4142135623730951);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1.5275252316519465);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1.707825127659933);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2.23606797749979);

--@test: standarddeviation - stddev_sample - DELIMITED
--@expected.error: io.confluent.ksql.util.KsqlException
--@expected.message: One of the functions used in the statement has an intermediate type that the value format can not handle. Please remove the function or change the format.
CREATE STREAM INPUT (ID STRING KEY, VALUE integer) WITH (kafka_topic='test_topic', value_format='DELIMITED');
CREATE TABLE OUTPUT AS SELECT ID, stddev_sample(value) AS stddev FROM INPUT group by ID;
--@test: standarddeviation - stddev_samp int
CREATE STREAM TEST (ID BIGINT KEY, VALUE integer) WITH (kafka_topic='test_topic',value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_samp(value) AS stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, 0);
INSERT INTO `TEST` (ID, value) VALUES (0, 10);
INSERT INTO `TEST` (ID, value) VALUES (100, 50);
INSERT INTO `TEST` (ID, value) VALUES (100, 10);
INSERT INTO `TEST` (ID, value) VALUES (0, 7);
INSERT INTO `TEST` (ID, value) VALUES (100, 3);
INSERT INTO `TEST` (ID, value) VALUES (100, NULL);
INSERT INTO `TEST` (ID, value) VALUES (0, 6);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 50.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 800.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 26.333333333333332);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 643.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 643.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 17.583333333333332);

--@test: standarddeviation - stddev_samp long
CREATE STREAM TEST (ID BIGINT KEY, VALUE bigint) WITH (kafka_topic='test_topic', value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_samp(value) as stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, 2147483648);
INSERT INTO `TEST` (ID, value) VALUES (0, 100);
INSERT INTO `TEST` (ID, value) VALUES (100, 500);
INSERT INTO `TEST` (ID, value) VALUES (100, 100);
INSERT INTO `TEST` (ID, value) VALUES (0, -2);
INSERT INTO `TEST` (ID, value) VALUES (100, 0);
INSERT INTO `TEST` (ID, value) VALUES (100, -6);
INSERT INTO `TEST` (ID, value) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2305842794465334300);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 80000.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1537228602658000400);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 70000.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 57275.666666666664);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 1537228602658000400);

--@test: standarddeviation - stddev_samp double
CREATE STREAM TEST (ID BIGINT KEY, VALUE double) WITH (kafka_topic='test_topic', value_format='AVRO');
CREATE TABLE OUTPUT as SELECT ID, stddev_samp(value) as stddev FROM test group by id;
INSERT INTO `TEST` (ID, value) VALUES (0, -1.8);
INSERT INTO `TEST` (ID, value) VALUES (0, 2.3);
INSERT INTO `TEST` (ID, value) VALUES (100, 9223372036854.775807);
INSERT INTO `TEST` (ID, value) VALUES (100, 300.8);
INSERT INTO `TEST` (ID, value) VALUES (0, 100.2);
INSERT INTO `TEST` (ID, value) VALUES (100, -200000.6);
INSERT INTO `TEST` (ID, value) VALUES (100, 0.0);
INSERT INTO `TEST` (ID, value) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 8.405);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 42535295862342920000000000.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 3334.2033333333347);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 28356864524046740000000000.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (100, 21267648239542927000000000.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 3334.2033333333347);

--@test: standarddeviation - stddev_samp double map
CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE map<varchar, double>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT as SELECT ID, stddev_samp(value['key1']) AS STDDEV FROM test group by id;
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=10.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=12.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=13.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=14.0, 'key2':=1.0));
INSERT INTO `TEST` (ID, name, value) VALUES (0, 'zero', MAP('key1':=16.0, 'key2':=1.0));
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 0.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2.0);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2.333333333333333);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 2.9166666666666665);
ASSERT VALUES `OUTPUT` (ID, STDDEV) VALUES (0, 5.0);

--@test: standarddeviation - stddev_samp - DELIMITED
--@expected.error: io.confluent.ksql.util.KsqlException
--@expected.message: One of the functions used in the statement has an intermediate type that the value format can not handle. Please remove the function or change the format.
CREATE STREAM INPUT (ID STRING KEY, VALUE integer) WITH (kafka_topic='test_topic', value_format='DELIMITED');
CREATE TABLE OUTPUT AS SELECT ID, stddev_samp(value) AS stddev FROM INPUT group by ID;
