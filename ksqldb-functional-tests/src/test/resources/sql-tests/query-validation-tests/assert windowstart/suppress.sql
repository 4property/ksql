--@test: suppress - should emit final result immediately at window end if grace is specified as zero
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 1, 0, 2);

--@test: suppress - should not emit final result before window end if grace is specified as zero
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);


--@test: suppress - should not emit before window end if no grace period given
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);


--@test: suppress - should emit at window end if no grace period given
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 1, 0, 2);

--@test: suppress - should include out of order events before window end plus grace period passes
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 4, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should drop out of order event after window end plus grace period passes
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 4, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should handle null values
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', NULL, 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', NULL, 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should drop events with no key
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (COL1, ROWTIME) VALUES ('v1', 1);
INSERT INTO `INPUT` (COL1, ROWTIME) VALUES ('v1', 2);
INSERT INTO `INPUT` (COL1, ROWTIME) VALUES ('v1', 1);
INSERT INTO `INPUT` (COL1, ROWTIME) VALUES ('v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 0, 0, 2);

--@test: suppress - should support final results for tumbling windows
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 4, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should support final results for tumbling windows with large jump
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 3);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 10);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 30);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 4, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 3, 2, 4);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 10, 10, 12);

--@test: suppress - should support final results for session windows
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 6 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 4);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 8);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 12);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 14);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 30);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 29);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 17);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 42);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 5, 14, 0, 14);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 30, 29, 30);

--@test: suppress - should support final results for hopping windows
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW HOPPING (SIZE 5 MILLISECONDS,ADVANCE BY 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 6);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 10);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 4, 2, 0, 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 3, 6, 2, 7);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 6, 4, 9);

--@test: suppress - should suppress multiple keys
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k2', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k2', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 5);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 'v1', 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k2', 'v1', 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 2, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k2', 2, 1, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should suppress after a filter WHERE clause
SET 'ksql.streams.__emit.interval.ms.kstreams.windowed.aggregation__' = '0';CREATE STREAM INPUT (ID STRING KEY, COL1 INT) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) WHERE COL1=1 GROUP BY ID EMIT FINAL;
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 1, 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 4, 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 1, 2);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 3, 1);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 2, 0);
INSERT INTO `INPUT` (ID, COL1, ROWTIME) VALUES ('k1', 1, 5);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 0, 0, 2);
ASSERT VALUES `OUTPUT` (ID, COUNT, ROWTIME, WINDOWSTART, WINDOWEND) VALUES ('k1', 1, 2, 2, 4);

--@test: suppress - should throw on non windowed tables
--@expected.error: io.confluent.ksql.util.KsqlException
--@expected.message: EMIT FINAL is only supported for windowed aggregations.
CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT GROUP BY ID EMIT FINAL;
--@test: suppress - should throw if no group by for aggregation
--@expected.error: io.confluent.ksql.util.KsqlException
--@expected.message: Non-aggregate SELECT expression(s) not part of GROUP BY
CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) EMIT FINAL;
--@test: suppress - should throw if no aggregation is present for group by
--@expected.error: io.confluent.ksql.util.KsqlException
--@expected.message: GROUP BY requires aggregate functions in either the SELECT or HAVING clause.
CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, COL1 FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;
