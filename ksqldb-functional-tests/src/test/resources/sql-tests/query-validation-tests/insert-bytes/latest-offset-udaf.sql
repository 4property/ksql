--@test: latest-offset-udaf - latest by offset with arrays, structs, and maps
CREATE STREAM INPUT (ID BIGINT KEY, F0 ARRAY<STRUCT<A VARCHAR, M MAP<STRING, DOUBLE>>>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, ARRAY[STRUCT(A:='Early0', M:=MAP('Early0':=1.234)), STRUCT(A:='Early2', M:=MAP('Early2':=1.23456))]);
INSERT INTO `INPUT` (ID, F0) VALUES (1, ARRAY[STRUCT(A:='Early1', M:=MAP('Early0':=2.345))]);
INSERT INTO `INPUT` (ID, F0) VALUES (0, ARRAY[STRUCT(A:='Later0', M:=MAP('Early0':=3.45))]);
INSERT INTO `INPUT` (ID, F0) VALUES (1, ARRAY[STRUCT(A:='Later1', M:=MAP('Early0':=4.56))]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[STRUCT(A:='Early0', M:=MAP('Early0':=1.234)), STRUCT(A:='Early2', M:=MAP('Early2':=1.23456))]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, ARRAY[STRUCT(A:='Early1', M:=MAP('Early0':=2.345))]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[STRUCT(A:='Later0', M:=MAP('Early0':=3.45))]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, ARRAY[STRUCT(A:='Later1', M:=MAP('Early0':=4.56))]);

--@test: latest-offset-udaf - latest by offset with maps
CREATE STREAM INPUT (ID BIGINT KEY, F0 MAP<STRING, DOUBLE>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, MAP('Early0':=1.234));
INSERT INTO `INPUT` (ID, F0) VALUES (1, MAP('Early1':=2.3456789));
INSERT INTO `INPUT` (ID, F0) VALUES (0, MAP('Later0':=3.6789));
INSERT INTO `INPUT` (ID, F0) VALUES (1, MAP('Later1':=4));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, MAP('Early0':=1.234));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, MAP('Early1':=2.3456789));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, MAP('Later0':=3.6789));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, MAP('Later1':=4.0));

--@test: latest-offset-udaf - latest by offset with structs
CREATE STREAM INPUT (ID BIGINT KEY, F0 STRUCT<A VARCHAR, B BIGINT>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, STRUCT(A:='Early0', B:=1));
INSERT INTO `INPUT` (ID, F0) VALUES (1, STRUCT(A:='Early1', B:=2));
INSERT INTO `INPUT` (ID, F0) VALUES (0, STRUCT(A:='Later0', B:=3));
INSERT INTO `INPUT` (ID, F0) VALUES (1, STRUCT(A:='Later1', B:=4));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, STRUCT(A:='Early0', B:=1));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, STRUCT(A:='Early1', B:=2));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, STRUCT(A:='Later0', B:=3));
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (1, STRUCT(A:='Later1', B:=4));

--@test: latest-offset-udaf - latest by offset with an array added
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT, F1 BIGINT, F2 DOUBLE, F3 BOOLEAN, F4 STRING, F5 TIMESTAMP, F6 TIME, F7 DATE, F8 BYTES, F9 ARRAY<INT>) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0, LATEST_BY_OFFSET(F1) AS L1, LATEST_BY_OFFSET(F2) AS L2, LATEST_BY_OFFSET(F3) AS L3, LATEST_BY_OFFSET(F4) AS L4, LATEST_BY_OFFSET(F5) AS L5, LATEST_BY_OFFSET(F6) AS L6, LATEST_BY_OFFSET(F7) AS L7, LATEST_BY_OFFSET(F8) AS L8, LATEST_BY_OFFSET(F9) AS L9 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8, F9) VALUES (0, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==', ARRAY[0, 0, 1, 0, -1]);
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8, F9) VALUES (1, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==', ARRAY[0, 0, 1, 0, -1]);
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8, F9) VALUES (0, 21, 2000, 2.23, false, 'foo', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==', ARRAY[1, 2, 3, 4, -1]);
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8, F9) VALUES (1, 21, 2000, 2.23, false, 'foo', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==', ARRAY[1, 2, 3, 4, -1]);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8, L9) VALUES (0, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==', ARRAY[0, 0, 1, 0, -1]);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8, L9) VALUES (1, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==', ARRAY[0, 0, 1, 0, -1]);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8, L9) VALUES (0, 21, 2000, 2.23, false, 'foo', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==', ARRAY[1, 2, 3, 4, -1]);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8, L9) VALUES (1, 21, 2000, 2.23, false, 'foo', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==', ARRAY[1, 2, 3, 4, -1]);

--@test: latest-offset-udaf - latest by offset
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT, F1 BIGINT, F2 DOUBLE, F3 BOOLEAN, F4 STRING, F5 TIMESTAMP, F6 TIME, F7 DATE, F8 BYTES) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0, LATEST_BY_OFFSET(F1) AS L1, LATEST_BY_OFFSET(F2) AS L2, LATEST_BY_OFFSET(F3) AS L3, LATEST_BY_OFFSET(F4) AS L4, LATEST_BY_OFFSET(F5) AS L5, LATEST_BY_OFFSET(F6) AS L6, LATEST_BY_OFFSET(F7) AS L7, LATEST_BY_OFFSET(F8) AS L8 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8) VALUES (0, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8) VALUES (1, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8) VALUES (0, 21, 2000, 2.23, false, 'bar', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4, F5, F6, F7, F8) VALUES (1, 21, 2000, 2.23, false, 'bar', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==');
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8) VALUES (0, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==');
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8) VALUES (1, 12, 1000, 1.23, true, 'foo', '1970-01-01T00:00:00.012', '00:00', '1973-05-19', 'YQ==');
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8) VALUES (0, 21, 2000, 2.23, false, 'bar', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==');
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4, L5, L6, L7, L8) VALUES (1, 21, 2000, 2.23, false, 'bar', '1970-01-01T00:00:00.034', '00:00', '1976-06-03', 'Yg==');

--@test: latest-offset-udaf - latest by offset with decimals
CREATE STREAM INPUT (ID BIGINT KEY, F0 DECIMAL(3,2)) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, true) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 3.4);
INSERT INTO `INPUT` (ID, F0) VALUES (0, 8.9);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 3.40);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 8.90);

--@test: latest-offset-udaf - nulls ignored - single
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, true) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 12);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, 13);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 12);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 12);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 13);

--@test: latest-offset-udaf - nulls ignored - multiple
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2, true) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 12);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, 13);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12, 13]);

--@test: latest-offset-udaf - nulls not ignored - single
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, false) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 12);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, 13);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 12);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, 13);

--@test: latest-offset-udaf - nulls not ignored - multiple
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2, false) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 12);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, 13);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12, NULL]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[NULL, 13]);

--@test: latest-offset-udaf - latest by offset with all nulls
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, NULL);

--@test: latest-offset-udaf - latest n by offset
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT, F1 BIGINT, F2 DOUBLE, F3 BOOLEAN, F4 STRING) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2) AS L0, LATEST_BY_OFFSET(F1, 2) AS L1, LATEST_BY_OFFSET(F2, 2) AS L2, LATEST_BY_OFFSET(F3, 2) AS L3, LATEST_BY_OFFSET(F4, 2) AS L4 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4) VALUES (0, 12, 1000, 1.23, true, 'foo');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4) VALUES (1, 12, 1000, 1.23, true, 'foo');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4) VALUES (0, 21, 2000, 2.23, false, 'bar');
INSERT INTO `INPUT` (ID, F0, F1, F2, F3, F4) VALUES (1, 21, 2000, 2.23, false, 'bar');
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4) VALUES (0, ARRAY[12], ARRAY[1000], ARRAY[1.23], ARRAY[true], ARRAY['foo']);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4) VALUES (1, ARRAY[12], ARRAY[1000], ARRAY[1.23], ARRAY[true], ARRAY['foo']);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4) VALUES (0, ARRAY[12, 21], ARRAY[1000, 2000], ARRAY[1.23, 2.23], ARRAY[true, false], ARRAY['foo', 'bar']);
ASSERT VALUES `OUTPUT` (ID, L0, L1, L2, L3, L4) VALUES (1, ARRAY[12, 21], ARRAY[1000, 2000], ARRAY[1.23, 2.23], ARRAY[true, false], ARRAY['foo', 'bar']);

--@test: latest-offset-udaf - latest n by offset with nulls
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0,2) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, 12);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[12]);

--@test: latest-offset-udaf - latest n by offset with all nulls
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0,2) AS L0 FROM INPUT GROUP BY ID;
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
INSERT INTO `INPUT` (ID, F0) VALUES (0, NULL);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[]);
ASSERT VALUES `OUTPUT` (ID, L0) VALUES (0, ARRAY[]);

--@test: latest-offset-udaf - merging session windows
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 3, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 2, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 3, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 2, 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - with nulls ignored
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 2, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 2, 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - with nulls ignored when merging
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 700, 0, 700);

--@test: latest-offset-udaf - merging session windows - with nulls not ignored
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, false) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 2, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 2, 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - with nulls not ignored when merging
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, false) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 700, 0, 700);

--@test: latest-offset-udaf - merging session windows - all nulls
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, false) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, NULL, 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - with nulls ignored - N
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2, true) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 2, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[1], 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[], 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[1, 2], 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - with nulls not ignored - N
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2, false) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 1, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, 2, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[1], 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[NULL], 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[NULL, 2], 1500, 0, 1500);

--@test: latest-offset-udaf - merging session windows - all nulls - N
CREATE STREAM INPUT (ID BIGINT KEY, F0 INT) WITH (kafka_topic='test_topic', value_format='JSON');
CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0, 2, false) AS L0 FROM INPUT WINDOW SESSION (1 SECONDS) GROUP BY ID;
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 0);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 1500);
INSERT INTO `INPUT` (ID, F0, ROWTIME) VALUES (0, NULL, 700);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[NULL], 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[NULL], 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 0, 0, 0);
ASSERT VALUES `OUTPUT` (ID, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, 1500, 1500, 1500);
ASSERT VALUES `OUTPUT` (ID, L0, ROWTIME, WINDOWSTART, WINDOWEND) VALUES (0, ARRAY[NULL, NULL], 1500, 0, 1500);

